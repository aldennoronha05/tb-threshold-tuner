# TB Threshold Tuner (Prevalence-Aware Triage)

An analyst-friendly Streamlit app to pick **safe** vs **efficient** operating thresholds for TB (tuberculosis) triage models on chest X-rays. It reads a simple CSV with `y_true` and `y_score`, shows key metrics, and exports “threshold cards” you can commit to your repo.

> Abbreviations (expanded once): **FN = False Negative**, **FNR = False Negative Rate**, **WLR = Workload Reduction**, **NPV = Negative Predictive Value**, **AUROC = Area Under the ROC curve**.

---

## Quickstart

```bash
pip install -r requirements.txt
streamlit run app/streamlit_app.py

-- Use the file uploader to load data/your_predictions.csv (or the included data/sample_predictions.csv).
-- Required columns: study_id (string), y_true (0/1), y_score (probability in [0,1]).
-- Move the Decision threshold slider and watch FNR, WLR, Sensitivity/Specificity, PPV/NPV, AUROC/AUPRC update in real time.
-- Click Save JSON to export a threshold card.

## Policy
-- This repo uses Policy B for “optimal/efficiency” scenarios:
-- Safe / Conservative: FN = 0 (zero misses; strict safety)
-- Optimal / Efficiency: FN ≤ 1 (allows one miss to maximize WLR while documenting the trade-off)
-- The helper script auto_policy_b.py automatically picks the highest threshold that satisfies the FN constraint (that choice maximizes WLR under the policy).


## Scenario (Policy B)
- Set the app sliders to each card’s Assumed prevalence (%) and Threshold to reproduce metrics.

```
| Case | Assumed prevalence | Threshold | FN | FNR | WLR | NPV | AUROC |
|---|---:|---:|---:|---:|---:|---:|---:|
| caseE_efficiency | 0.70% | 0.5496 | 1 | 9.09% | 99.45% | 99.95% | 0.9998 |
| caseH_optimal | 4.00% | 0.5496 | 1 | 9.09% | 99.45% | 99.95% | 0.9998 |
| caseH_safe | 4.00% | 0.4932 | 0 | 0.00% | 99.25% | 100.00% | 0.9998 |
| caseL_optimal | 0.50% | 0.5496 | 1 | 9.09% | 99.45% | 99.95% | 0.9998 |
| caseL_safe | 0.50% | 0.4932 | 0 | 0.00% | 99.25% | 100.00% | 0.9998 |
| caseM_optimal | 1.50% | 0.5496 | 1 | 9.09% | 99.45% | 99.95% | 0.9998 |
| caseM_safe | 1.50% | 0.4932 | 0 | 0.00% | 99.25% | 100.00% | 0.9998 |
| caseQ_conservative | 0.50% | 0.4932 | 0 | 0.00% | 99.25% | 100.00% | 0.9998 |

## Provenance & reproducibility
- **Dataset for examples:** `data/sample_predictions.csv` (low-prevalence synthetic set).
- **Cards generated by:** python auto_policy_b.py --csv data/sample_predictions.csv --outdir cases
- **Summary table built with:** `python summarize_cases.py   # writes cases/CASE_SUMMARY.md

- **How to reproduce on your data:**
  python auto_policy_b.py --csv data/your_predictions.csv --outdir cases
  python summarize_cases.py

## Reproduce on your data
- Place your predictions at data/your_predictions.csv with columns:
- study_id (string), y_true (0/1), y_score (probability ∈ [0,1])
- Auto-tune per Policy B and build cards + summary:

python auto_policy_b.py --csv data/your_predictions.csv --outdir cases
python summarize_cases.py   # writes cases/CASE_SUMMARY.md

## Reference and inspiration
Scenario design (safe vs optimal thresholds, prevalence-aware interpretation) inspired by:
Munjal, P., Al Mahrooqi, A., Rajan, R., Jeremijenko, A., Ahmad, I., Akhtar, M. I., Pimentel, M. A. F., & Khan, S.
Population-scale cross-sectional observational study for AI-powered TB screening on one million CXRs.
(NPJ Digital Journal / https://rdcu.be/eBqTN)

## Medical-use disclaimer

- This repository is for research and demonstration only. It is not a medical device and must not be used for clinical decision-making. Metrics (including FNR, WLR, NPV) are dataset- and site-dependent and may not generalize.